动态规划算法要求马尔可夫决策过程是已知的, 即要求与智能体交互的环境是完全已知的（例如迷宫或者给定规则的网格世界）. 在此条件下, 智能体其实并不需要和环境真正交互来采样数据, 直接用动态规划算法就可以解出最优价值或策略

然而, 对于大部分强化学习现实场景（例如电子游戏或者一些复杂物理环境）, 其马尔可夫决策过程的状态转移概率是无法写出来的, 也就无法直接进行动态规划. 在这种情况下, 智能体只能和环境进行交互, 通过采样到的数据来学习, 这类学习方法统称为*无模型的强化学习（model-free reinforcement learning）*



